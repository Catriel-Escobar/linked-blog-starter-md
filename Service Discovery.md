---
tags: [service-discovery, networking, microservices, dns, load-balancing, registration]
date: 2026-01-06
related: [Kubernetes, Container Orchestration, Networking, Microservices Architecture]
status: reference
---

# Service Discovery

## üìã ¬øQu√© es Service Discovery?

El mecanismo para que **servicios encuentren y se conecten a otros servicios** autom√°ticamente, sin hardcodear direcciones IP.

**Problema:** En microservicios, servicios aparecen y desaparecen constantemente (deployments, restarts, scaling). ¬øC√≥mo sabe gateway d√≥nde est√° auth-service?

**Analog√≠a:** Registro de oficinas:
- ‚ùå Sin service discovery: "Auth-service est√° en 192.168.1.42:50051" ‚Üí Cambio IP, gateway se rompe
- ‚úÖ Con service discovery: "Necesito auth-service" ‚Üí Sistema busca "service registry" ‚Üí Retorna direcci√≥n actual

---

## üéØ Problema que Resuelve

### Sin Service Discovery

```
Configuraci√≥n hardcoded:
‚îú‚îÄ gateway: AUTH_SERVICE_HOST=192.168.1.42:50051
‚îú‚îÄ gateway: ORDER_SERVICE_HOST=192.168.1.43:5000
‚îî‚îÄ gateway: PAYMENT_SERVICE_HOST=192.168.1.44:8080

Cuando auth-service se mueve (redeploy):
‚îú‚îÄ IP cambia a 192.168.1.100
‚îú‚îÄ Gateway sigue intentando 192.168.1.42
‚îú‚îÄ Conexiones fallan
‚îî‚îÄ Requiere redeploy de gateway (downtime)

Resultado: Fr√°gil, propenso a fallos
```

### Con Service Discovery

```
Registro din√°mico:
‚îú‚îÄ auth-service: "Hola, soy auth-service en 192.168.1.42:50051"
‚îú‚îÄ order-service: "Hola, soy order-service en 192.168.1.43:5000"
‚îî‚îÄ payment-service: "Hola, soy payment-service en 192.168.1.44:8080"

Cuando auth-service se redeploya:
‚îú‚îÄ Nuevo pod se levanta en 192.168.1.100:50051
‚îú‚îÄ Se registra en service registry
‚îú‚îÄ Viejo pod: desregistrado
‚îú‚îÄ Gateway quiere conectar: "¬øD√≥nde auth-service?"
‚îú‚îÄ Registry responde: 192.168.1.100:50051
‚îî‚îÄ Conexi√≥n autom√°tica, sin cambios

Resultado: Resiliente, autom√°tico
```

---

## üèóÔ∏è Tipos de Service Discovery

### 1. **Client-Side Discovery**

```
Cliente (Gateway):
1. Consulta Service Registry: "¬øD√≥nde est√° auth-service?"
2. Registry retorna: [192.168.1.42:50051, 192.168.1.43:50051]
3. Cliente elige una (load balancing)
4. Conecta a servidor seleccionado

Ventajas: Simple, control total del cliente
Desventajas: Cliente hace load balancing, l√≥gica duplicada
```

### 2. **Server-Side Discovery**

```
Cliente (Gateway):
1. Conecta a Load Balancer: lb.service.internal:50051
2. Load Balancer consulta Service Registry
3. Load Balancer elige backend
4. Load Balancer forwards tr√°fico

Ventajas: Cliente simple, load balancing centralizado
Desventajas: Punto central de fallo
```

---

## üíª Implementaciones

### 1. **Kubernetes (Built-in)**

```yaml
# Auth Service - Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: auth-service
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: auth-service  # Label cr√≠tico
    spec:
      containers:
      - name: auth
        image: auth-service:1.0

---
# Auth Service - Service (Service Discovery)
apiVersion: v1
kind: Service
metadata:
  name: auth-service  # Nombre DNS: auth-service.default.svc.cluster.local
spec:
  selector:
    app: auth-service  # Selecciona Pods con este label
  ports:
  - port: 50051
    targetPort: 50051
  type: ClusterIP
```

En Kubernetes, cliente usa DNS:
```go
// gateway/internal/handlers/auth.go
// Kubernetes inyecta autom√°ticamente:
// AUTH_SERVICE_HOST=auth-service.default.svc.cluster.local
// AUTH_SERVICE_PORT=50051

conn, _ := grpc.Dial(
    "auth-service.default.svc.cluster.local:50051",
    grpc.WithInsecure(),
)
```

### 2. **Consul (Standalone)**

```go
// Service Registration
package main

import (
    "github.com/hashicorp/consul/api"
)

func registerService() error {
    client, _ := api.NewClient(api.DefaultConfig())
    
    // Registrar este servicio
    registration := &api.AgentServiceRegistration{
        ID:      "auth-service-1",
        Name:    "auth-service",
        Port:    50051,
        Address: "192.168.1.42",
        Check: &api.AgentServiceCheck{
            HTTP:     "http://192.168.1.42:8080/health",
            Interval: "10s",
            Timeout:  "5s",
        },
    }
    
    return client.Agent().ServiceRegister(registration)
}

// Service Discovery
func discoverService(serviceName string) ([]string, error) {
    client, _ := api.NewClient(api.DefaultConfig())
    
    // Consultar servicio
    services, _, _ := client.Health().Service(serviceName, "", true, nil)
    
    var addresses []string
    for _, service := range services {
        addr := fmt.Sprintf("%s:%d", service.Service.Address, service.Service.Port)
        addresses = append(addresses, addr)
    }
    
    return addresses, nil
}

func main() {
    // Registrar
    registerService()
    
    // Descubrir
    addrs, _ := discoverService("auth-service")
    fmt.Println("Auth service instances:", addrs)
}
```

### 3. **Eureka (Netflix)**

```go
import "github.com/hudl/fargo"

func registerWithEureka() error {
    instance := &fargo.Instance{
        InstanceID: "auth-service-1",
        HostName:   "auth-service.example.com",
        App:        "AUTH-SERVICE",
        IPAddr:     "192.168.1.42",
        Port:       50051,
        Status:     fargo.UP,
        HomePageURL: "http://192.168.1.42:8080",
        HealthCheckURL: "http://192.168.1.42:8080/health",
    }
    
    conn, _ := fargo.NewConnWithPath("http://eureka-server:8080/eureka/")
    return conn.RegisterInstance(instance)
}

func discoverWithEureka(appName string) ([]*fargo.Instance, error) {
    conn, _ := fargo.NewConnWithPath("http://eureka-server:8080/eureka/")
    app, _ := conn.GetApp(appName)
    return app.Instances, nil
}
```

### 4. **DNS SRV Records**

```bash
# DNS SRV Record
_auth._tcp.service.consul.  IN SRV  0 0 50051 auth-1.node.consul.
_auth._tcp.service.consul.  IN SRV  0 0 50051 auth-2.node.consul.

# Resolver autom√°ticamente encuentra todos
```

---

## üéØ Tu Proyecto: Service Discovery

### Kubernetes + Gateway

```go
// gateway/internal/handlers/auth.go
package handlers

import (
    "fmt"
    "os"
    "google.golang.org/grpc"
    pb "github.com/myapp/auth-service/proto"
)

type AuthHandler struct {
    authClient pb.AuthServiceClient
}

func NewAuthHandler() *AuthHandler {
    // Service discovery: Kubernetes
    // Direcci√≥n: auth-service:50051 (Kubernetes DNS autom√°tico)
    authServiceHost := os.Getenv("AUTH_SERVICE_HOST")
    if authServiceHost == "" {
        authServiceHost = "auth-service:50051"
    }
    
    conn, err := grpc.Dial(
        authServiceHost,
        grpc.WithInsecure(),
        grpc.WithDefaultCallOptions(
            grpc.MaxCallRecvMsgSize(1024*1024*10), // 10MB
        ),
    )
    if err != nil {
        panic(err)
    }
    
    return &AuthHandler{
        authClient: pb.NewAuthServiceClient(conn),
    }
}

func (h *AuthHandler) Register(w http.ResponseWriter, r *http.Request) {
    var req RegisterRequest
    json.NewDecoder(r.Body).Decode(&req)
    
    // Service discovery maneja la conexi√≥n
    user, err := h.authClient.Register(r.Context(), &pb.RegisterRequest{
        Email:    req.Email,
        Password: req.Password,
    })
    
    if err != nil {
        w.WriteHeader(http.StatusInternalServerError)
        return
    }
    
    w.WriteJSON(user)
}
```

### Con Load Balancer en Kubernetes

```yaml
# Kubernetes Service with load balancing
apiVersion: v1
kind: Service
metadata:
  name: auth-service
spec:
  type: ClusterIP  # Internal load balancer
  selector:
    app: auth-service
  ports:
  - port: 50051
    targetPort: 50051
  sessionAffinity: ClientIP  # Sticky sessions (opcional)
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 10800
```

Kubernetes autom√°ticamente:
- Descubre 3 pods de auth-service
- Balancea tr√°fico entre ellos
- Si un pod falla, lo remueve del pool
- Si se levanta nuevamente, lo agrega

---

## üìä Patrones de Service Discovery

### Pattern 1: DNS

```go
// Simple DNS lookup
func discoverServiceByDNS(serviceName string) (string, error) {
    addrs, err := net.LookupHost(serviceName)
    if err != nil {
        return "", err
    }
    
    if len(addrs) == 0 {
        return "", fmt.Errorf("no hosts found")
    }
    
    // En producci√≥n, implementar load balancing
    return addrs[0], nil
}
```

### Pattern 2: Client-Side Load Balancing

```go
import "google.golang.org/grpc"

// gRPC con client-side load balancing
func dialAuthService() (*grpc.ClientConn, error) {
    // M√∫ltiples endpoints (descubiertos de registro)
    targets := []string{
        "auth-1.service.consul:50051",
        "auth-2.service.consul:50051",
        "auth-3.service.consul:50051",
    }
    
    // gRPC round-robin autom√°tico
    conn, err := grpc.Dial(
        fmt.Sprintf("///", targets...), // Round-robin resolver
        grpc.WithDefaultServiceConfig(`{
            "loadBalancingConfig": [{"round_robin":{}}]
        }`),
        grpc.WithInsecure(),
    )
    
    return conn, err
}
```

### Pattern 3: Health Check Integration

```go
// Service registry con health checks
type ServiceRegistry struct {
    client *api.Client
}

func (sr *ServiceRegistry) RegisterWithHealthCheck(
    serviceName string,
    addr string,
    port int,
    healthCheckURL string,
) error {
    registration := &api.AgentServiceRegistration{
        ID:      fmt.Sprintf("%s-%s", serviceName, addr),
        Name:    serviceName,
        Address: addr,
        Port:    port,
        Check: &api.AgentServiceCheck{
            HTTP:     healthCheckURL,
            Interval: "10s",  // Revisar cada 10s
            Timeout:  "5s",   // Timeout de 5s
            DeregisterCriticalServiceAfter: "30s", // Remover si 30s unhealthy
        },
    }
    
    return sr.client.Agent().ServiceRegister(registration)
}
```

---

## ‚ö° Best Practices

‚úÖ **Usa Kubernetes nativo si est√°s en K8s**
‚úÖ **Implementa health checks**
‚úÖ **Cachea respuestas de discovery localmente**
‚úÖ **Reintentar con backoff exponencial**
‚úÖ **Monitorea service registry**
‚úÖ **Usa circuit breaker + service discovery**

---

## ‚ö†Ô∏è Antipatrones

‚ùå Hardcodear IPs en configuraci√≥n
‚ùå Sin health checks
‚ùå Descubrir en cada request (muy lento)
‚ùå Ignorar cambios de topolog√≠a
‚ùå Sin timeout en lookups
‚ùå Fallar si registry no responde (no tener fallbacks)

---

## üîó Service Discovery + Other Patterns

```
Service Discovery
‚îú‚îÄ [[Kubernetes]] ‚Üê Native
‚îú‚îÄ [[Load Balancing]] ‚Üê Distribuciones de tr√°fico
‚îú‚îÄ [[Circuit Breaker Pattern]] ‚Üê Manejo de fallos
‚îú‚îÄ [[Graceful Shutdown]] ‚Üê Deregistraci√≥n limpia
‚îî‚îÄ [[Observability]] ‚Üê Monitoreo de servicios
```

---

## üìö Recursos

### Kubernetes
- Services: https://kubernetes.io/docs/concepts/services-networking/service/
- Service Discovery: https://kubernetes.io/docs/concepts/services-networking/

### Consul
- Service Discovery: https://www.consul.io/docs/discovery/dns
- Client API: https://pkg.go.dev/github.com/hashicorp/consul/api

### Otros
- Eureka: https://github.com/Netflix/eureka
- etcd: https://etcd.io/

---

## üíº En Entrevistas

**Pregunta:** "¬øC√≥mo hace tu gateway saber d√≥nde est√° el auth-service?"

**Respuesta:**
> "Usar√≠a service discovery. En Kubernetes, es autom√°tico: defin√≠ un Service resource que selecciona todos los Pods con label `app: auth-service`. Kubernetes autom√°ticamente crea una entrada DNS: `auth-service.default.svc.cluster.local` que resuelve a las IPs de todos los Pods. En el gateway, conecto a ese hostname: `grpc.Dial('auth-service:50051')`. Kubernetes autom√°ticamente balancea tr√°fico entre las 3 replicas. Si un Pod muere, Kubernetes lo remueve del pool de IPs. Si se levanta uno nuevo, lo agrega. Resultado: gateway nunca necesita saber IPs espec√≠ficas. Si estuviera en ambiente standalone sin Kubernetes, usar√≠a Consul: auth-service se registra al startup ('Hola, soy auth-service en 192.168.1.42:50051'), gateway consulta Consul ('¬øD√≥nde auth-service?'), Consul retorna las instancias disponibles. Importante: health checks - Consul revisa peri√≥dicamente si auth-service responde, si no, lo remueve autom√°ticamente. Sin service discovery, tendr√≠a que hardcodear direcciones IP en configuraci√≥n del gateway, cada cambio requerir√≠a redeploy."

---

#service-discovery #microservices #kubernetes #networking #devops
