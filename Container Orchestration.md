---
tags: [container-orchestration, docker, kubernetes, microservices, deployment, scaling]
date: 2026-01-06
related: [Kubernetes, Docker, Container Registries, Service Discovery, Networking]
status: reference
---

# Container Orchestration

## ðŸ“‹ Â¿QuÃ© es Container Orchestration?

Un **sistema que automatiza el despliegue, scaling y manejo de contenedores** en un cluster.

**AnalogÃ­a:** Director de orquesta:
- âŒ Sin orquestaciÃ³n: Cada mÃºsico decide cuÃ¡ndo tocar, si se cansa se va, nadie sabe cuÃ¡ndo terminar
- âœ… Con orquestaciÃ³n: Director dice "violas, 3 copias", "si una se cansa, reemplazarla", "cuando alguien se equivoca, repetir", sincronizaciÃ³n perfecta

---

## ðŸŽ¯ Problemas que Resuelve

### Sin Container Orchestration

```
Manual:
âŒ Deployar: docker run en cada servidor
âŒ Scaling: SSH a servidor, docker run mÃºltiples veces
âŒ Fallos: Monitorear cada contenedor, relanzar manualmente
âŒ Networking: Configurar puertos, networking entre mÃ¡quinas
âŒ Storage: Montar volÃºmenes manualmente
âŒ Actualizaciones: Matar containers, esperar reconexiones
âŒ Logs: Ssh a cada servidor para ver logs

Resultado: DevOps es 100% operacional, 0% innovation
```

### Con Container Orchestration

```
Declarativo:
âœ… Deployar: kubectl apply -f deployment.yaml
âœ… Scaling: kubectl scale replicas=10
âœ… Fallos: Auto-restart de containers
âœ… Networking: AutomÃ¡tico entre contenedores
âœ… Storage: PersistentVolumes, automÃ¡tico
âœ… Actualizaciones: Rolling deployment, zero downtime
âœ… Logs: kubectl logs, agregados

Resultado: DevOps es 20% operacional, 80% innovation
```

---

## ðŸ—ï¸ Componentes de Orchestration

### 1. **Scheduling**

```
Problema: "Tengo 100 containers, 10 servidores, Â¿dÃ³nde pongo cada uno?"

Orquestador:
â”œâ”€ Analiza recursos cada servidor
â”œâ”€ Analiza requirements de container
â”œâ”€ Calcula mejor placement
â””â”€ Asigna container a servidor

Ejemplo:
â”Œâ”€ Servidor 1: CPU=50%, Memory=60%
â”œâ”€ Servidor 2: CPU=30%, Memory=40%
â”œâ”€ Servidor 3: CPU=80%, Memory=90%
â”‚
â”œâ”€ Container app-web (CPU=20%, RAM=512MB)
â”‚  â””â”€ Placement: Servidor 2 (mejor fit)
â”‚
â””â”€ Container db (CPU=40%, RAM=4GB)
   â””â”€ Placement: Servidor 1 (mÃ¡s recursos)
```

### 2. **Replication & Scaling**

```
Usuario declara:
"Necesito 5 instancias de auth-service siempre"

Orquestador:
â”œâ”€ Ve: 3 instancias corriendo
â”œâ”€ AcciÃ³n: Levanta 2 mÃ¡s
â”œâ”€ Resultado: 5 instancias

Cuando trÃ¡fico sube:
â”œâ”€ Monitorea CPU/Memory
â”œâ”€ Ve: CPU > 80%
â”œâ”€ Auto-scales: Levanta a 8 instancias
â”œâ”€ Resultado: CPU normaliza a 60%
```

### 3. **Health Management**

```
Orquestador continuamente:
â”œâ”€ Revisa: Â¿Container sigue vivo? (liveness probe)
â”œâ”€ Revisa: Â¿Listo para trÃ¡fico? (readiness probe)
â”œâ”€ Si muere: Levanta automÃ¡ticamente
â”œâ”€ Si timeout health check: Mata y reinicia

Ejemplo timeline:
10:00 - auth-service-1 se levanta
10:05 - Health check: OK
10:10 - Health check: OK
10:15 - Database falla, auth-service se congela
10:16 - Health check: FAIL, timeout
10:17 - Orquestador mata container y relanza
10:22 - Database vuelve, nuevo container conecta
10:30 - Servicio disponible sin intervenciÃ³n manual
```

### 4. **Networking**

```
Orquestador:
â”œâ”€ Service Discovery: Â¿DÃ³nde estÃ¡ el servicio?
â”œâ”€ Load Balancing: Distribuye trÃ¡fico
â”œâ”€ Network Policies: QuiÃ©n puede hablar con quiÃ©n
â””â”€ Ingress: Acceso externo

Ejemplo:
gateway (Pod 1) necesita auth-service
â”œâ”€ Pregunta: "Â¿DÃ³nde auth-service?"
â”œâ”€ Orquestador: "10.0.0.5:50051, 10.0.0.6:50051, 10.0.0.7:50051"
â”œâ”€ gateway: Conecta a 10.0.0.5
â”œâ”€ 10.0.0.5 muere, siguiente request va a 10.0.0.6
â””â”€ Auto load-balanced
```

### 5. **Storage**

```
Orquestador maneja:
â”œâ”€ Ephemeral: Datos temporales del container
â”œâ”€ Persistent: Datos que surviven container muertes
â”‚  â”œâ”€ PersistentVolumes: Storage pool
â”‚  â”œâ”€ PersistentVolumeClaims: Solicitud de storage
â”‚  â””â”€ Binding automÃ¡tico
â”‚
â””â”€ ConfigMaps/Secrets: ConfiguraciÃ³n e secretos

Ejemplo:
DB container necesita /data/postgres
â”œâ”€ Declara: "Necesito 100GB PersistentVolume"
â”œâ”€ Orquestador: Busca PV disponible
â”œâ”€ Monta automÃ¡ticamente
â”œâ”€ Container muere, PV persiste
â”œâ”€ Nuevo container monta mismo PV
â””â”€ Datos preserved
```

### 6. **Update & Rollback**

```
Deployment de v1.0 â†’ v2.0:

Sin orquestaciÃ³n (manual):
â”œâ”€ Kill v1 containers
â”œâ”€ Start v2 containers
â”œâ”€ Downtime: 30s-2min

Con orquestaciÃ³n (rolling):
â”œâ”€ Start v2 container #1
â”œâ”€ Verify health: OK
â”œâ”€ Kill v1 container #1
â”œâ”€ Start v2 container #2
â”œâ”€ Verify health: OK
â”œâ”€ Kill v1 container #2
â”œâ”€ ... repeat
â””â”€ Zero downtime, gradual rollout

Si v2 tiene bug:
â”œâ”€ Rollback a v1 con 1 comando
â””â”€ Sistema preserva estado de v2 (para debugging)
```

---

## ðŸ’» Principales Orquestadores

### 1. **Kubernetes**

```yaml
# Declarativo, state-driven
apiVersion: apps/v1
kind: Deployment
metadata:
  name: auth-service
spec:
  replicas: 3
  selector:
    matchLabels:
      app: auth-service
  template:
    metadata:
      labels:
        app: auth-service
    spec:
      containers:
      - name: auth
        image: auth-service:1.0.0
```

**Ventajas:**
- âœ… MÃ¡s poderoso
- âœ… Comunidad enorme
- âœ… EstÃ¡ndar de industria
- âœ… Todos los cloud providers soportan

**Desventajas:**
- âŒ Curva aprendizaje pronunciada
- âŒ Complexity overhead
- âŒ Overkill para aplicaciones simples

### 2. **Docker Swarm**

```bash
# Declarativo, mÃ¡s simple que K8s
docker service create \
  --name auth-service \
  --replicas 3 \
  --publish 50051:50051 \
  auth-service:1.0.0
```

**Ventajas:**
- âœ… Mucho mÃ¡s simple que K8s
- âœ… Built-in en Docker
- âœ… Menos recursos

**Desventajas:**
- âŒ Menos features que K8s
- âŒ Comunidad menor
- âŒ Menos adoption

### 3. **Nomad (HashiCorp)**

```hcl
job "auth-service" {
  datacenters = ["dc1"]
  type        = "service"

  group "api" {
    count = 3

    task "auth" {
      driver = "docker"

      config {
        image = "auth-service:1.0.0"
        ports = ["grpc"]
      }

      resources {
        cpu    = 500
        memory = 256
      }
    }
  }
}
```

**Ventajas:**
- âœ… Multi-cloud nativo
- âœ… Flexible (containers, VMs, bare metal)
- âœ… IntegraciÃ³n con Consul

**Desventajas:**
- âŒ Menos adoption que K8s
- âŒ Comunidad menor

### 4. **Docker Compose (Local)**

```yaml
version: '3.8'

services:
  postgres:
    image: postgres:15-alpine
    ports:
      - "5432:5432"
    environment:
      POSTGRES_PASSWORD: password

  auth-service:
    build: ./auth-service
    ports:
      - "50051:50051"
    environment:
      DATABASE_URL: postgres://postgres:password@postgres:5432/auth
    depends_on:
      - postgres

  gateway:
    build: ./gateway
    ports:
      - "8080:8080"
    environment:
      AUTH_SERVICE_HOST: auth-service:50051
    depends_on:
      - auth-service
```

**Ventajas:**
- âœ… Perfecto para desarrollo local
- âœ… Simple
- âœ… Multi-container fÃ¡cil

**Desventajas:**
- âŒ Solo local, no production-ready
- âŒ Sin scaling automÃ¡tico
- âŒ Sin self-healing

---

## ðŸŽ¯ Tu Proyecto: Container Orchestration

### Development: Docker Compose

```bash
# Tu setup actual
docker-compose up

# AutomÃ¡ticamente:
â”œâ”€ Levanta postgres
â”œâ”€ Levanta auth-service (dependencia)
â””â”€ Levanta gateway (dependencia)

# Networking automÃ¡tico:
â”œâ”€ gateway â†” auth-service: auth-service:50051
â”œâ”€ auth-service â†” postgres: postgres:5432
â””â”€ Todo en red `myapp_default`
```

### Production: Kubernetes

```yaml
# kube/namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: myapp

---
# kube/postgres-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: postgres
  namespace: myapp
spec:
  replicas: 1
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
    spec:
      containers:
      - name: postgres
        image: postgres:15-alpine
        ports:
        - containerPort: 5432
        env:
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: password
        volumeMounts:
        - name: postgres-storage
          mountPath: /var/lib/postgresql/data
      volumes:
      - name: postgres-storage
        persistentVolumeClaim:
          claimName: postgres-pvc

---
# kube/auth-service-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: auth-service
  namespace: myapp
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  selector:
    matchLabels:
      app: auth-service
  template:
    metadata:
      labels:
        app: auth-service
    spec:
      containers:
      - name: auth
        image: auth-service:1.0.0
        ports:
        - name: grpc
          containerPort: 50051
        - name: health
          containerPort: 8080
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: database-url
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "500m"

---
# kube/auth-service-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: auth-service
  namespace: myapp
spec:
  selector:
    app: auth-service
  ports:
  - name: grpc
    port: 50051
    targetPort: 50051
  type: ClusterIP

---
# kube/gateway-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: gateway
  namespace: myapp
spec:
  replicas: 2
  selector:
    matchLabels:
      app: gateway
  template:
    metadata:
      labels:
        app: gateway
    spec:
      containers:
      - name: gateway
        image: gateway:1.0.0
        ports:
        - name: http
          containerPort: 8080
        env:
        - name: AUTH_SERVICE_HOST
          value: "auth-service.myapp.svc.cluster.local:50051"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5

---
# kube/gateway-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: gateway
  namespace: myapp
spec:
  selector:
    app: gateway
  ports:
  - name: http
    port: 80
    targetPort: 8080
  type: LoadBalancer
```

---

## ðŸ“Š Comparativa Orquestadores

```
Feature           | K8s    | Swarm  | Nomad  | Compose
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Complexity        | High   | Low    | Medium | Very Low
Learning Curve    | Hard   | Easy   | Medium | Easy
Scaling Auto      | Yes    | Yes    | Yes    | No
Multi-cloud       | Yes    | Limited| Yes    | No
StatefulSets      | Yes    | No     | Yes    | No
Networking        | Advanced| Simple | Medium | Simple
Adoption          | Huge   | Small  | Medium | Dev Only
Production Ready  | Yes    | Yes    | Yes    | No
Community         | Huge   | Small  | Medium | Large
Cost              | High   | Low    | Medium | Free
```

---

## âš¡ Best Practices

âœ… **Conoce herramientas de tu orquestador**
âœ… **Define resource requests/limits**
âœ… **Implementa health checks**
âœ… **Monitorea cluster**
âœ… **Automatiza deployments (CI/CD)**
âœ… **Prepara disaster recovery**
âœ… **Documenta runbooks**

---

## âš ï¸ Antipatrones

âŒ Seleccionar orquestador sin evaluar necesidades
âŒ Sin planning de recursos
âŒ Sin backup/DR plan
âŒ Manual deployments
âŒ Sin monitoring/alerting
âŒ Ignorar security

---

## ðŸ”— Ecosystem OrquestaciÃ³n

```
Container Orchestration
â”œâ”€ [[Kubernetes]] â† EstÃ¡ndar
â”œâ”€ [[Docker]] â† Runtime
â”œâ”€ [[Service Discovery]] â† Networking
â”œâ”€ [[Container Registries]] â† Image storage
â”œâ”€ [[CI/CD]] â† Deployments
â”œâ”€ [[Monitoring]] â† Prometheus/Grafana
â””â”€ [[Logging]] â† ELK/Loki
```

---

## ðŸ“š Recursos

### Kubernetes
- Official Docs: https://kubernetes.io/docs/
- Interactive Tutorial: https://kubernetes.io/docs/tutorials/

### Docker
- Swarm: https://docs.docker.com/engine/swarm/
- Compose: https://docs.docker.com/compose/

### Nomad
- Docs: https://www.nomadproject.io/docs
- Job Spec: https://www.nomadproject.io/docs/job-specification

### Comparativas
- CNCF Landscape: https://landscape.cncf.io/
- Container Orchestration Comparison: Medium articles

---

## ðŸ’¼ En Entrevistas

**Pregunta:** "Â¿QuÃ© herramienta de orquestaciÃ³n usarÃ­as y por quÃ©?"

**Respuesta:**
> "Depende del contexto. Para un startup, Docker Compose localmente + AWS ECS o Heroku en production. Simple, mantenible, low ops overhead. Para una empresa con mÃºltiples servicios, Kubernetes. Es el estÃ¡ndar de industria, todos los cloud providers lo soportan (EKS, GKE, AKS), comunidad enorme, muy flexible. En mi auth-service + gateway, usarÃ­a Kubernetes: defino Deployments para cada servicio (3 replicas auth-service, 2 replicas gateway), Services para networking (auth-service:50051 automÃ¡ticamente balancea entre replicas), Ingress para exposiciÃ³n externa con TLS. Orquestador maneja: scheduling (Â¿dÃ³nde pongo cada container?), scaling (si CPU > 80%, agregar replicas), health checks (si container falla, relanzar), rolling updates (v1.0 â†’ v2.0 sin downtime), storage persistente (postgres data persiste si pod muere). Sin orquestador, todo manual. Con orquestador, es declarativo: digo 'necesito 3 auth-services', K8s lo mantiene. Superior."

---

#container-orchestration #kubernetes #docker #deployment #microservices
